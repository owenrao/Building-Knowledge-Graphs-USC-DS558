{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZJo-SDru5oU"
      },
      "source": [
        "# HW2 Text Clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZslX_FyvHn6",
        "outputId": "45106d31-1835-48f3-874e-58f1ca77370d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.24.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1At7zYgMu5oX",
        "outputId": "d4590493-0c37-4b49-f8ea-d63ea8b3c617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encode the corpus. This might take a while\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "# We donwload the Quora Duplicate Questions Dataset (https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)\n",
        "# and find similar question in it\n",
        "url = \"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
        "dataset_path = \"quora_duplicate_questions.tsv\"\n",
        "max_corpus_size = 5000  # We limit our corpus to only the first 50k questions\n",
        "\n",
        "\n",
        "# Check if the dataset exists. If not, download and extract\n",
        "# Download dataset if needed\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Download dataset\")\n",
        "    util.http_get(url, dataset_path)\n",
        "\n",
        "# Get all unique sentences from the file\n",
        "corpus_sentences = set()\n",
        "with open(dataset_path, encoding='utf8') as fIn:\n",
        "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_MINIMAL)\n",
        "    for row in reader:\n",
        "        corpus_sentences.add(row['question1'])\n",
        "        corpus_sentences.add(row['question2'])\n",
        "        if len(corpus_sentences) >= max_corpus_size:\n",
        "            break\n",
        "\n",
        "corpus_sentences = list(corpus_sentences)\n",
        "print(\"Encode the corpus. This might take a while\")\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "corpus_embeddings = embedder.encode(corpus_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv3r17Rsu5oZ"
      },
      "source": [
        "## 2-3: Embedding dimension reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6PZF_Qxtu5oZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sentence_transformers import SentenceTransformer, LoggingHandler, util, evaluation, models, InputExample\n",
        "import os\n",
        "import gzip\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6f5Kl272u5oa"
      },
      "outputs": [],
      "source": [
        "new_dimension = 128\n",
        "#Compute PCA on the train embeddings matrix\n",
        "pca = PCA(n_components=new_dimension)\n",
        "reduced_emb = pca.fit_transform(corpus_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_emb.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz49gJetxo9Z",
        "outputId": "5c6fd1ce-d0e9-4631-a256-547259f8a8d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.cluster import KMeans\n",
        "# Perform kmean clustering\n",
        "num_clusters = 5\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "clustering_model.fit(reduced_emb)\n",
        "cluster_assignment = clustering_model.labels_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct5mbk_F-Hnh",
        "outputId": "cdb7343d-0acb-495c-9add-9c03f4d7d179"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.54 s, sys: 1.07 s, total: 2.61 s\n",
            "Wall time: 1.49 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(cluster_assignment))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWzHBzyMZuvc",
        "outputId": "6872fecd-d90e-4df3-b127-0cbfdb434c5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "clustering_model = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average', distance_threshold=1) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
        "clustering_model.fit(reduced_emb)\n",
        "cluster_assignment = clustering_model.labels_"
      ],
      "metadata": {
        "id": "SF_HLM8k_iRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75907f7b-302f-404a-9d8d-9845b4dc91b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.09 s, sys: 15.8 ms, total: 2.1 s\n",
            "Wall time: 2.09 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(cluster_assignment))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdv3gejoZwx9",
        "outputId": "eaa3f3f6-9eb3-4217-ea1c-18e9987e1fbe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('newenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "87ef2c4983d124858e7bc65373e634017d4d0da0a01665b9091a743c5bc24cc8"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}