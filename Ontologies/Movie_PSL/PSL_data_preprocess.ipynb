{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rltk\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import re\n",
    "# You can use this tokenizer in case you need to manipulate some data\n",
    "tokenizer = rltk.tokenizer.crf_tokenizer.crf_tokenizer.CrfTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(doc):\n",
    "    return set(re.findall(r\"\\w+\", doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_score(a,b):\n",
    "    n = len(a.intersection(b))\n",
    "    u = len(a.union(b))\n",
    "    return n/u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sw_score(a,b):\n",
    "    match_score = 2\n",
    "    mismatch_score = -1\n",
    "    matrix = swalign.NucleotideScoringMatrix(match_score, mismatch_score)\n",
    "    lalignment_object = swalign.LocalAlignment(matrix)\n",
    "    alignment_object = lalignment_object.align(str(a), str(b))\n",
    "    try:\n",
    "        return alignment_object.matches/(alignment_object.matches+alignment_object.mismatches)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDB(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title(self):\n",
    "        return self.raw_object['Title']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def title_tokens(self):\n",
    "        return my_tokenizer(self.raw_object['Title'])\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def date(self):\n",
    "        try:\n",
    "            return str(parser.parse(self.raw_object['Year']).date())\n",
    "        except:\n",
    "            return f\"IMDB Item {self.id} has no valid publish year record\"\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def director(self):\n",
    "        return self.raw_object['Director']\n",
    "\n",
    "class Rotten_TMT(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def title(self):\n",
    "        return self.raw_object['Title']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def title_tokens(self):\n",
    "        return my_tokenizer(self.raw_object['Title'])\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def date(self):\n",
    "        try:\n",
    "            return str(parser.parse(self.raw_object['Year']).date())\n",
    "        except:\n",
    "            return f\"RottenTMT Item {self.id} has no valid publish year record\"\n",
    "    \n",
    "    @rltk.cached_property\n",
    "    def director(self):\n",
    "        return self.raw_object['Director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ds = rltk.Dataset(rltk.CSVReader(open(\"raw_data/imdb.csv\", encoding=\"UTF8\")),record_class=IMDB)\n",
    "rt_tmt_ds = rltk.Dataset(rltk.CSVReader(open(\"raw_data/rotten_tomatoes.csv\", encoding=\"UTF8\")),record_class=Rotten_TMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = rltk.HashBlockGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens_block = bg.generate(\n",
    "    bg.block(imdb_ds, function_=lambda r: \",\".join(r.title_tokens)),\n",
    "    bg.block(rt_tmt_ds, function_=lambda r: \",\".join(r.title_tokens))\n",
    ") #0.50,0.97\n",
    "\n",
    "date_block = bg.generate(\n",
    "    bg.block(imdb_ds, property_='date'),\n",
    "    bg.block(rt_tmt_ds, property_='date')\n",
    ") #0.23,0.80\n",
    "\n",
    "author_block = bg.generate(\n",
    "    bg.block(imdb_ds, property_='director'),\n",
    "    bg.block(rt_tmt_ds, property_='director')\n",
    ") #0.69,0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = list(rltk.get_record_pairs(imdb_ds, rt_tmt_ds, block=name_tokens_block))\n",
    "for pair in rltk.get_record_pairs(imdb_ds, rt_tmt_ds, block=author_block):\n",
    "    if pair not in candidate_pairs:\n",
    "        candidate_pairs.append(pair)\n",
    "for pair in rltk.get_record_pairs(imdb_ds, rt_tmt_ds, block=date_block):\n",
    "    if pair not in candidate_pairs:\n",
    "        candidate_pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = set()\n",
    "for r1,r2 in candidate_pairs:\n",
    "    ci.add(r1.id)\n",
    "    ci.add(r2.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdi = [(i.id, j.id) for i,j in candidate_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv(\"raw_data/imdb.csv\")\n",
    "rotten_tmt = pd.read_csv(\"raw_data/rotten_tomatoes.csv\")\n",
    "labeled_dt = pd.read_csv(\"raw_data/labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_title = imdb[[\"ID\",\"Title\"]].dropna()\n",
    "imdb_title.to_csv(\"data/imdb_title.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_director = imdb[[\"ID\",\"Director\"]].dropna()\n",
    "imdb_director.to_csv(\"data/imdb_director.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_date = imdb[[\"ID\",\"Year\"]].dropna()\n",
    "imdb_date[\"Year\"] = imdb_date[\"Year\"].apply(lambda x: parser.parse(x).date())\n",
    "imdb_date.to_csv(\"data/imdb_date.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_year = imdb_date\n",
    "imdb_year[\"Year\"] = imdb_date[\"Year\"].apply(lambda x: str(x.year))\n",
    "with open('data/imdb_date.txt', 'w', newline='', encoding='UTF8') as file:\n",
    "        for line in imdb_date.values:\n",
    "            r1,r2 = line\n",
    "            if r1 in ci:\n",
    "                file.write(\"\\t\".join([r1, r2])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes_title = rotten_tmt[[\"ID\",\"Title\"]].dropna()\n",
    "rotten_tomatoes_title.to_csv(\"data/rotten_tomatoes_title.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes_director = rotten_tmt[[\"ID\",\"Director\"]].dropna()\n",
    "rotten_tomatoes_director.to_csv(\"data/rotten_tomatoes_director.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes_date = rotten_tmt[[\"ID\",\"Year\"]].dropna()\n",
    "rotten_tomatoes_date[\"Year\"] = rotten_tomatoes_date[\"Year\"].apply(lambda x: parser.parse(x).date())\n",
    "rotten_tomatoes_date.to_csv(\"data/rotten_tomatoes_date.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes_year = rotten_tomatoes_date\n",
    "rotten_tomatoes_year[\"Year\"] = rotten_tomatoes_date[\"Year\"].apply(lambda x: x.year)\n",
    "with open('data/rotten_tomatoes_year.txt', 'w', newline='', encoding='UTF8') as file:\n",
    "        for line in rotten_tomatoes_date.values:\n",
    "            r1,r2 = line\n",
    "            if r1 in ci:\n",
    "                file.write(\"\\t\".join([r1, str(r2)])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/same_movie_target.txt', 'w', newline='', encoding='UTF8') as file:\n",
    "        for r1, r2 in candidate_pairs:\n",
    "            file.write(\"\\t\".join([r1.id, r2.id])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_movie_truth = labeled_dt[[\"ltable.ID\",\"rtable.ID\",\"gold\"]].dropna()\n",
    "same_movie_truth[\"ltable.ID\"] = same_movie_truth[\"ltable.ID\"].apply(lambda x: \"a-\"+str(x))\n",
    "same_movie_truth[\"rtable.ID\"] = same_movie_truth[\"rtable.ID\"].apply(lambda x: \"b-\"+str(x))\n",
    "same_movie_truth.to_csv(\"data/same_movie_truth.txt\", index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_title_token = imdb_title\n",
    "imdb_title_token[\"Title_Tokens\"] = imdb_title_token.apply(lambda x: my_tokenizer(x[1]), axis=1)\n",
    "rotten_tmt_title_token = rotten_tomatoes_title\n",
    "rotten_tmt_title_token[\"Title_Tokens\"] = rotten_tmt_title_token.apply(lambda x: my_tokenizer(x[1]), axis=1)\n",
    "similar_title = imdb_title_token.merge(rotten_tmt_title_token,how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_title[\"similar\"] = similar_title.apply(lambda x: jaccard_score(x[2],x[5]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_title = similar_title[similar_title[\"similar\"]>=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_title_id = similar_title[[\"ID_x\",\"ID_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3393"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_title_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/similar_title_id.txt', 'w', newline='', encoding='UTF8') as file:\n",
    "        for line in similar_title_id.values:\n",
    "            r1,r2 = line\n",
    "            if (r1,r2) in cdi:\n",
    "                file.write(\"\\t\".join([r1, r2])+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87ef2c4983d124858e7bc65373e634017d4d0da0a01665b9091a743c5bc24cc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
