{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuQvvpzl1KFn",
        "outputId": "1506f5e5-a0d0-4946-d9a0-bd750a32453b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "#!pip install torch\n",
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BuufsZW1RdV"
      },
      "source": [
        "Change torch.__version__ of following installation command.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-XDBJWC1NKb",
        "outputId": "68570ff9-f315-486c-9d9c-fe50c5e5c012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 31.9 MB/s \n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 32.5 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=7bfbff4fb427342edb779a6c617038ab55832a98c010c57e96c38060fc7435bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-sparse, torch-scatter, torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1 torch-scatter-2.0.9 torch-sparse-0.6.15\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzmywOKX64q9"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa71S04A69Tc",
        "outputId": "4f3a4821-01da-402e-a53a-1a4f8bf1bba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/IMDB-BINARY.zip\n",
            "Extracting /tmp/imdb/IMDB-BINARY/IMDB-BINARY.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.utils import degree\n",
        "import torch_geometric.transforms as T\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "dataset = TUDataset(root='/tmp/imdb', name='IMDB-BINARY')\n",
        "\n",
        "### add code for using the node degree as input features.\n",
        "if dataset.data.x is None:\n",
        "  max_degree = 0\n",
        "  degs = []\n",
        "  for data in dataset:\n",
        "      degs += [degree(data.edge_index[0], dtype=torch.long)]\n",
        "      max_degree = max(max_degree, degs[-1].max().item())\n",
        "\n",
        "  if max_degree < 1000:\n",
        "      dataset.transform = T.OneHotDegree(max_degree)\n",
        "  else:\n",
        "      deg = torch.cat(degs, dim=0).to(torch.float)\n",
        "      mean, std = deg.mean().item(), deg.std().item()\n",
        "      dataset.transform = NormalizedDegree(mean, std)\n",
        "### add train, val, test loader.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset,[800,100,100])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "BczvxlwnguO2",
        "outputId": "93e3b0fd-a886-44f9-e6d5-fcda2d3e294f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a2e520a46ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Step {step + 1}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'======='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of graphs in the current batch: {data.num_graphs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9o5Cmdg_JOw"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9owzc4n_Ivc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, 16)\n",
        "        self.conv3 = GCNConv(16, 16)\n",
        "        self.lin1 = Linear(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        ### You can add more layers or alter the model structure. See geometric documents which layer or model you can use.\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        ### Pass aggregated representation to linear layer to make final prediction\n",
        "        #x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.lin1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvWzPpdO1tUA"
      },
      "source": [
        "Train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VsB7RDR1XPm"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O7At9Td18N9"
      },
      "source": [
        "Validation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSIBQfM017Hc"
      },
      "outputs": [],
      "source": [
        "def val(loader):\n",
        "    model.eval()\n",
        "    loss_all = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "    return loss_all / len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K7uh53LAQ85"
      },
      "source": [
        "Test function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1STWHVtmAR3e"
      },
      "outputs": [],
      "source": [
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output = model(data)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFpnv-5U1-dK"
      },
      "source": [
        "Main code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(EPOCH, m, o, LOSS):\n",
        "  torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': m.state_dict(),\n",
        "            'optimizer_state_dict': o.state_dict(),\n",
        "            'loss': LOSS,\n",
        "            }, \"model_checkpoint.md\")"
      ],
      "metadata": {
        "id": "PeNs8S68zPqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "WPIzRwgQDdm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqw5zHpyAYC7"
      },
      "outputs": [],
      "source": [
        "model = GCN()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "number_of_epochs = 300 # You can change.\n",
        "\n",
        "lowest_loss = float('inf')\n",
        "for epoch in range(number_of_epochs):\n",
        "    train_loss = train()\n",
        "    #print(\"train_loss:\",train_loss)\n",
        "    val_loss = val(val_loader)\n",
        "    print(\"val_loss:\",val_loss)\n",
        "    # Choose the lowest validation loss checkpoint (you can implement early stopping as well)\n",
        "    if val_loss < lowest_loss:\n",
        "      lowest_loss = val_loss\n",
        "      save_checkpoint(epoch,model,optimizer,lowest_loss)\n",
        "# Load the lowest validation loss checkpoint and check the performance.\n",
        "checkpoint = torch.load(\"model_checkpoint.md\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "test_acc = test(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "id": "2Yjh4F8cM_p4",
        "outputId": "797f1f9d-547f-46fd-928c-7c1c2dcdf881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymh2qsAT17iU"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}