{"cells":[{"cell_type":"markdown","metadata":{"id":"rV3ck1wXJ3xL","pycharm":{"name":"#%% md\n"}},"source":["# Task 1: Using RLTK to perform Entity Resolution (ER)\n","\n","<sub>Content of this notebook was prepared by Basel Shbita, and modified by Avijit Thawani (thawani@usc.edu) as part of the class <u>DSCI 558: Building Knowledge Graphs</u> at University of Southern California (USC).</sub>"]},{"cell_type":"markdown","metadata":{"id":"vKYLgCLPJ3xN","pycharm":{"name":"#%% md\n"}},"source":["The Record Linkage ToolKit ([RLTK](https://github.com/usc-isi-i2/rltk)) is a general-purpose open-source record linkage platform that allows users to build powerful Python programs that link records referring to the same underlying entity.\n","\n","This notebook introduces some applied examples using RLTK. You can also find additional examples and use-cases in [RLTK's documentation](https://rltk.readthedocs.io/en/master/)."]},{"cell_type":"markdown","metadata":{"id":"z2Q5FfqkJ3xN","pycharm":{"name":"#%% md\n"}},"source":["## Dataset analysis & RLTK components construction"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"fTlKyPqCJ3xO","outputId":"f8d02d9d-601c-4c75-e48e-842d5dba3de7","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rltk\n","  Downloading rltk-2.0.0a20-py3-none-any.whl (81 kB)\n","     ---------------------------------------- 81.5/81.5 kB 1.5 MB/s eta 0:00:00\n","Collecting dask>=0.19.2\n","  Downloading dask-2022.9.0-py3-none-any.whl (1.1 MB)\n","     ---------------------------------------- 1.1/1.1 MB 2.7 MB/s eta 0:00:00\n","Collecting scipy>=1.1.0\n","  Downloading scipy-1.9.1-cp310-cp310-win_amd64.whl (38.6 MB)\n","     ---------------------------------------- 38.6/38.6 MB 2.4 MB/s eta 0:00:00\n","Collecting pyrallel.lib\n","  Downloading pyrallel.lib-0.0.10-py3-none-any.whl (24 kB)\n","Collecting matplotlib>=2.0.0\n","  Downloading matplotlib-3.5.3-cp310-cp310-win_amd64.whl (7.2 MB)\n","     ---------------------------------------- 7.2/7.2 MB 2.4 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from rltk) (1.23.2)\n","Collecting Cython>=0.28.0\n","  Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n","     -------------------------------------- 986.3/986.3 kB 2.5 MB/s eta 0:00:00\n","Collecting pandas>=1.2.0\n","  Downloading pandas-1.4.4-cp310-cp310-win_amd64.whl (10.0 MB)\n","     ---------------------------------------- 10.0/10.0 MB 2.4 MB/s eta 0:00:00\n","Collecting distributed>=1.23\n","  Downloading distributed-2022.9.0-py3-none-any.whl (902 kB)\n","     -------------------------------------- 902.4/902.4 kB 2.4 MB/s eta 0:00:00\n","Collecting toolz>=0.8.2\n","  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n","     ---------------------------------------- 55.8/55.8 kB 2.8 MB/s eta 0:00:00\n","Collecting cloudpickle>=1.1.1\n","  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n","Collecting partd>=0.3.10\n","  Downloading partd-1.3.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from dask>=0.19.2->rltk) (21.3)\n","Collecting fsspec>=0.6.0\n","  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n","     -------------------------------------- 140.8/140.8 kB 2.1 MB/s eta 0:00:00\n","Collecting pyyaml>=5.3.1\n","  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n","     -------------------------------------- 151.7/151.7 kB 2.2 MB/s eta 0:00:00\n","Collecting locket>=1.0.0\n","  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n","Collecting msgpack>=0.6.0\n","  Downloading msgpack-1.0.4-cp310-cp310-win_amd64.whl (61 kB)\n","     ---------------------------------------- 61.3/61.3 kB 1.6 MB/s eta 0:00:00\n","Requirement already satisfied: urllib3 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from distributed>=1.23->rltk) (1.26.11)\n","Requirement already satisfied: click>=6.6 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from distributed>=1.23->rltk) (8.1.3)\n","Requirement already satisfied: tornado<6.2,>=6.0.3 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from distributed>=1.23->rltk) (6.1)\n","Collecting sortedcontainers!=2.0.0,!=2.0.1\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Collecting zict>=0.1.3\n","  Downloading zict-2.2.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: jinja2 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from distributed>=1.23->rltk) (3.1.2)\n","Collecting tblib>=1.6.0\n","  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: psutil>=5.0 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from distributed>=1.23->rltk) (5.9.0)\n","Collecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n","     ---------------------------------------- 55.3/55.3 kB 1.5 MB/s eta 0:00:00\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n","     -------------------------------------- 957.2/957.2 kB 2.4 MB/s eta 0:00:00\n","Collecting pillow>=6.2.0\n","  Downloading Pillow-9.2.0-cp310-cp310-win_amd64.whl (3.3 MB)\n","     ---------------------------------------- 3.3/3.3 MB 2.3 MB/s eta 0:00:00\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from matplotlib>=2.0.0->rltk) (3.0.9)\n","Collecting cycler>=0.10\n","  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n","Collecting pytz>=2020.1\n","  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n","     -------------------------------------- 500.6/500.6 kB 2.6 MB/s eta 0:00:00\n","Collecting multiprocess>=0.70\n","  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n","     -------------------------------------- 133.1/133.1 kB 2.6 MB/s eta 0:00:00\n","Collecting dill>=0.3\n","  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n","     ---------------------------------------- 95.8/95.8 kB 2.8 MB/s eta 0:00:00\n","Collecting typing>=3.6\n","  Downloading typing-3.7.4.3.tar.gz (78 kB)\n","     ---------------------------------------- 78.6/78.6 kB 2.2 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: colorama in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from click>=6.6->distributed>=1.23->rltk) (0.4.5)\n","Requirement already satisfied: six>=1.5 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->rltk) (1.16.0)\n","Collecting heapdict\n","  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ruiji\\anaconda3\\envs\\ds558\\lib\\site-packages (from jinja2->distributed>=1.23->rltk) (2.1.1)\n","Building wheels for collected packages: typing\n","  Building wheel for typing (setup.py): started\n","  Building wheel for typing (setup.py): finished with status 'done'\n","  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26306 sha256=2b5590ddb0ac9e2d17dfb2c2232b02017c4382158ffe11d1c756b0302888c40f\n","  Stored in directory: c:\\users\\ruiji\\appdata\\local\\pip\\cache\\wheels\\7c\\d0\\9e\\1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n","Successfully built typing\n","Installing collected packages: sortedcontainers, pytz, msgpack, heapdict, zict, typing, toolz, tblib, scipy, pyyaml, pillow, locket, kiwisolver, fsspec, fonttools, dill, Cython, cycler, cloudpickle, partd, pandas, multiprocess, matplotlib, pyrallel.lib, dask, distributed, rltk\n","Successfully installed Cython-0.29.32 cloudpickle-2.2.0 cycler-0.11.0 dask-2022.9.0 dill-0.3.5.1 distributed-2022.9.0 fonttools-4.37.1 fsspec-2022.8.2 heapdict-1.0.1 kiwisolver-1.4.4 locket-1.0.0 matplotlib-3.5.3 msgpack-1.0.4 multiprocess-0.70.13 pandas-1.4.4 partd-1.3.0 pillow-9.2.0 pyrallel.lib-0.0.10 pytz-2022.2.1 pyyaml-6.0 rltk-2.0.0a20 scipy-1.9.1 sortedcontainers-2.4.0 tblib-1.7.0 toolz-0.12.0 typing-3.7.4.3 zict-2.2.0\n"]}],"source":["!pip install rltk"]},{"cell_type":"markdown","metadata":{"id":"K8fyiwzJJ3xP","pycharm":{"name":"#%% md\n"}},"source":["### Task 1-1. Construct RLTK Datasets\n","\n","First, you need define how a single entry would like for each type of record (for each dataset)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"We7cQGTRJ3xP","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import rltk\n","import csv\n","\n","# You can use this tokenizer in case you need to manipulate some data\n","tokenizer = rltk.tokenizer.crf_tokenizer.crf_tokenizer.CrfTokenizer()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"T3Q_rPqmJ3xP","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["'''\n","Feel free to add more columns here for use in record linkage.\n","'''\n","\n","class GoodRecord(rltk.Record):\n","    def __init__(self, raw_object):\n","        super().__init__(raw_object)\n","        self.name = ''\n","\n","    @rltk.cached_property\n","    def id(self):\n","        return self.raw_object['ID']\n","\n","    @rltk.cached_property\n","    def name_string(self):\n","        return self.raw_object['Title']\n","\n","    @rltk.cached_property\n","    def name_tokens(self):\n","        return set(tokenizer.tokenize(self.name_string))\n","\n","class NobleRecord(rltk.Record):\n","    def __init__(self, raw_object):\n","        super().__init__(raw_object)\n","        self.name = ''\n","\n","    @rltk.cached_property\n","    def id(self):\n","        return self.raw_object['ID']\n","\n","    @rltk.cached_property\n","    def name_string(self):\n","        return self.raw_object['Title']\n","    \n","    @rltk.cached_property\n","    def name_tokens(self):\n","        return set(tokenizer.tokenize(self.name_string))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cZ2VHWnwJ3xQ","pycharm":{"name":"#%%\n"}},"outputs":[{"ename":"UnicodeDecodeError","evalue":"'gbk' codec can't decode byte 0x93 in position 3442: illegal multibyte sequence","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[1;32mc:\\Users\\ruiji\\Documents\\USC\\Fall2022\\DS558\\Homework\\HW2\\ER_KR.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ruiji/Documents/USC/Fall2022/DS558/Homework/HW2/ER_KR.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m good_file \u001b[39m=\u001b[39m dir_ \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgoodreads.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ruiji/Documents/USC/Fall2022/DS558/Homework/HW2/ER_KR.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m noble_file \u001b[39m=\u001b[39m dir_ \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbarnes_and_nobles.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ruiji/Documents/USC/Fall2022/DS558/Homework/HW2/ER_KR.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ds1 \u001b[39m=\u001b[39m rltk\u001b[39m.\u001b[39;49mDataset(rltk\u001b[39m.\u001b[39;49mCSVReader(good_file),record_class\u001b[39m=\u001b[39;49mGoodRecord)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ruiji/Documents/USC/Fall2022/DS558/Homework/HW2/ER_KR.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ds2 \u001b[39m=\u001b[39m rltk\u001b[39m.\u001b[39mDataset(rltk\u001b[39m.\u001b[39mCSVReader(noble_file),record_class\u001b[39m=\u001b[39mNobleRecord)\n","File \u001b[1;32mc:\\Users\\ruiji\\anaconda3\\envs\\DS558\\lib\\site-packages\\rltk\\dataset.py:56\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, reader, record_class, adapter, size, sampling_function, pp_num_of_processor, pp_max_size_per_mapper_queue)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# add data\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m reader:\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_records(reader, size, pp_num_of_processor, pp_max_size_per_mapper_queue)\n","File \u001b[1;32mc:\\Users\\ruiji\\anaconda3\\envs\\DS558\\lib\\site-packages\\rltk\\dataset.py:86\u001b[0m, in \u001b[0;36mDataset.add_records\u001b[1;34m(self, reader, size, pp_num_of_processor, pp_max_size_per_mapper_queue)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m# serial\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39mif\u001b[39;00m pp_num_of_processor \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter\u001b[39m.\u001b[39mparallel_safe:\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mfor\u001b[39;00m raw_object \u001b[39min\u001b[39;00m reader:\n\u001b[0;32m     87\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_function \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_function(raw_object):\n\u001b[0;32m     88\u001b[0m             generate(raw_object)\n","File \u001b[1;32mc:\\Users\\ruiji\\anaconda3\\envs\\DS558\\lib\\site-packages\\rltk\\io\\reader\\csv_reader.py:21\u001b[0m, in \u001b[0;36mCSVReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_csv_reader:\n\u001b[0;32m     22\u001b[0m         \u001b[39myield\u001b[39;00m {t[\u001b[39m0\u001b[39m]: t[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39mitems()}\n","File \u001b[1;32mc:\\Users\\ruiji\\anaconda3\\envs\\DS558\\lib\\csv.py:110\u001b[0m, in \u001b[0;36mDictReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_num \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    109\u001b[0m         \u001b[39m# Used only for its side effect.\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfieldnames\n\u001b[0;32m    111\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader)\n\u001b[0;32m    112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_num \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mline_num\n","File \u001b[1;32mc:\\Users\\ruiji\\anaconda3\\envs\\DS558\\lib\\csv.py:97\u001b[0m, in \u001b[0;36mDictReader.fieldnames\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fieldnames \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fieldnames \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreader)\n\u001b[0;32m     98\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m         \u001b[39mpass\u001b[39;00m\n","\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0x93 in position 3442: illegal multibyte sequence"]}],"source":["dir_ = ''\n","good_file = dir_ + 'goodreads.csv'\n","noble_file = dir_ + 'barnes_and_nobles.csv'\n","\n","ds1 = rltk.Dataset(rltk.CSVReader(good_file),record_class=GoodRecord)\n","ds2 = rltk.Dataset(rltk.CSVReader(noble_file),record_class=NobleRecord)"]},{"cell_type":"markdown","metadata":{"id":"4XHgnuhJJ3xQ","pycharm":{"name":"#%% md\n"}},"source":["You can load your csv files into RLTK using this method:"]},{"cell_type":"markdown","metadata":{"id":"KIylouixJ3xQ","pycharm":{"name":"#%% md\n"}},"source":["And we can inspect a few entries:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CUrpjGTJ3xQ","outputId":"498d3b0e-a742-4740-8751-3a348661e5d0","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["  id                                 name_string  \\\n","0  0          Managing My Life: My Autobiography   \n","1  1     I Remember: Sketch for an Autobiography   \n","2  2              Betty Boothroyd: Autobiography   \n","3  3  Caddie, A Sydney Barmaid: An Autobiography   \n","4  4     Nureyev: An Autobiography With Pictures   \n","\n","                                         name_tokens  \n","0             {My, Life, :, Managing, Autobiography}  \n","1   {I, an, Sketch, Autobiography, for, :, Remember}  \n","2               {:, Betty, Autobiography, Boothroyd}  \n","3  {Caddie, A, An, ,, Barmaid, Sydney, :, Autobio...  \n","4    {Nureyev, An, Pictures, With, :, Autobiography}  \n","  id                                        name_string  \\\n","0  0          Pioneer Girl: The Annotated Autobiography   \n","1  1  American Sniper (Movie Tie-in Edition): The Au...   \n","2  2                     The Autobiography of Malcolm X   \n","3  3                           Assata: An Autobiography   \n","4  4                            Autobiography of a Yogi   \n","\n","                                         name_tokens  \n","0  {Annotated, Pioneer, Girl, :, The, Autobiography}  \n","1  {Lethal, ), American, Military, Edition, the, ...  \n","2               {X, Malcolm, of, The, Autobiography}  \n","3                     {Assata, An, Autobiography, :}  \n","4                       {of, a, Yogi, Autobiography}  \n"]}],"source":["# print some entries\n","print(ds1.generate_dataframe().head(5))\n","print(ds2.generate_dataframe().head(5))"]},{"cell_type":"markdown","metadata":{"id":"MB0HHqDpJ3xR"},"source":["### Task 1-2. Blocking\n","\n","First, we'll load dev set to evaluate both blocking (Task 1-2) and entity linking (Task 1-3)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfGah0DhJ3xR","outputId":"762cc35a-df00-46f4-fb8f-0200a600bd71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Column names are: goodreads.ID, barnes_and_nobles.ID, label\n","Processed 297 lines.\n"]},{"data":{"text/plain":["<rltk.evaluation.trial.Trial at 0x16236e7a0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dev_set_file = dir_ + 'dev.csv'\n","dev = []\n","with open(dev_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","    line_count = 0\n","    for row in csv_reader:\n","        if len(row) <= 1:\n","            continue\n","        if line_count == 0:\n","            columns = row\n","            line_count += 1\n","        else:\n","            dev.append(row)\n","    print(f'Column names are: {\", \".join(columns)}')\n","    print(f'Processed {len(dev)} lines.')\n","\n","gt = rltk.GroundTruth()\n","for row in dev:    \n","    r1 = ds1.get_record(row[0])\n","    r2  = ds2.get_record(row[1])\n","    if row[-1] == '1':\n","        gt.add_positive(r1.raw_object['ID'], r2.raw_object['ID'])\n","    else:\n","        gt.add_negative(r1.raw_object['ID'], r2.raw_object['ID'])\n","\n","rltk.Trial(gt)"]},{"cell_type":"markdown","metadata":{"id":"aJ07ud86J3xR"},"source":["Then, you can build your own blocking techniques and evaluate it.\n","\n","Hint:\n","\n","- What is the total number of pairs without blocking? \n","- what is the number of paris with blocking?\n","- After blocking, how many \"correct\" (matched) pairs presented in dev set?\n"]},{"cell_type":"markdown","metadata":{"id":"OCpi3AqZJ3xR","pycharm":{"name":"#%% md\n"}},"source":["### Task 1-3. Entity Linking"]},{"cell_type":"markdown","metadata":{"id":"98xt8o9kJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Here are 2 example functions for field (attribute) similarity:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQ3jFoFSJ3xS","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["def name_string_similarity_1(r1, r2):\n","    ''' Example dummy similiary function '''\n","    s1 = r1.name_string[:3]\n","    s2 = r2.name_string[:3]\n","    \n","    return rltk.jaro_winkler_similarity(s1, s2)\n","    \n","def name_string_similarity_2(r1, r2):\n","    ''' Example dummy similiary function '''\n","    s1 = r1.name_string\n","    s2 = r2.name_string\n","    \n","    if s1 == s2:\n","        return 1\n","    \n","    return 0"]},{"cell_type":"markdown","metadata":{"id":"9peeajHNJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Here's how you can combine multiple similarity functions into a single weightened scoring function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGf52bBcJ3xS","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["# threshold value to determine if we are confident the record match\n","MY_TRESH = 0.8 # this number is just an example, you need to change it\n","\n","# entity linkage scoring function\n","def rule_based_method(r1, r2):\n","    score_1 = name_string_similarity_1(r1, r2)\n","    score_2 = name_string_similarity_2(r1, r2)\n","    \n","    total = 0.7 * score_1 + 0.3 * score_2\n","    \n","    # return two values: boolean if they match or not, float to determine confidence\n","    return total > MY_TRESH, total"]},{"cell_type":"markdown","metadata":{"id":"WLbrTPamJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Lets run some candidates using the ground-truth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xo9-fdimJ3xS","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["trial = rltk.Trial(gt)\n","candidate_pairs = rltk.get_record_pairs(ds1, ds2, ground_truth=gt)\n","for r1, r2 in candidate_pairs:\n","    result, confidence = rule_based_method(r1, r2)\n","    trial.add_result(r1, r2, result, confidence)"]},{"cell_type":"markdown","metadata":{"id":"tqhybHyKJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Now lets evaluate our trial results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PJlbaUcJ3xS","outputId":"bce6863d-2ee2-4b6d-90cd-90029742cd60","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial statistics based on Ground-Truth from development set data:\n","tp: 0.597015 [40]\n","fp: 0.052174 [12]\n","tn: 0.947826 [218]\n","fn: 0.402985 [27]\n"]}],"source":["trial.evaluate()\n","print('Trial statistics based on Ground-Truth from development set data:')\n","print(f'tp: {trial.true_positives:.06f} [{len(trial.true_positives_list)}]')\n","print(f'fp: {trial.false_positives:.06f} [{len(trial.false_positives_list)}]')\n","print(f'tn: {trial.true_negatives:.06f} [{len(trial.true_negatives_list)}]')\n","print(f'fn: {trial.false_negatives:.06f} [{len(trial.false_negatives_list)}]')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ximXdpDkJ3xS","outputId":"dde53833-1f7b-4b4e-9f0a-66682b58bde0","pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/plain":["0.6722689075630253"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["trial.f_measure"]},{"cell_type":"markdown","metadata":{"id":"32c-kCWqJ3xT","pycharm":{"name":"#%% md\n"}},"source":["### Save Test predictions\n","You will be evaluated on dev and test predictions, over a hidden ground truth."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1qkfFDrJ3xT","outputId":"8bed2f96-0065-4893-e9ac-21d8e44ced53","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Column names are: goodreads.ID, barnes_and_nobles.ID\n","Processed 100 lines.\n"]}],"source":["test_set_file = dir_ + 'test.csv'\n","test = []\n","with open(test_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","    line_count = 0\n","    for row in csv_reader:\n","        if len(row) <= 1:\n","            continue\n","        if line_count == 0:\n","            columns = row\n","            line_count += 1\n","        else:\n","            test.append(row)\n","    print(f'Column names are: {\", \".join(columns)}')\n","    print(f'Processed {len(test)} lines.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfC2TKISJ3xT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["predictions = []\n","for id1, id2 in test:\n","    r1 = ds1.get_record(id1)\n","    r2  = ds2.get_record(id2)\n","    result, confidence = rule_based_method(r1, r2)\n","    predictions.append((r1.id, r2.id, result, confidence))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UCWB2Q6J3xT","outputId":"5a2d2a1d-3c4a-4d87-da59-89cc94ee6f8b","pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/plain":["(100, 3967, 3701)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(predictions), len(ds1.generate_dataframe()), len(ds2.generate_dataframe())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnxUzg4WJ3xT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["with open(dir_ + 'predictions.csv', mode='w') as file:\n","    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    for row in predictions:\n","        writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"G7svOwNGJ3xT","pycharm":{"name":"#%% md\n"}},"source":["# Task 2: Using RDFLib for Knowledge Representation"]},{"cell_type":"markdown","metadata":{"id":"RDtcKE-kJ3xT","pycharm":{"name":"#%% md\n"}},"source":["RDFLib is a Python library for working with RDF, a simple yet powerful language for representing information as graphs. RDFLib aims to be a pythonic RDF API, a Graph is a python collection of RDF Subject, Predicate,  Object Triples.\n","\n","This notebook introduces simple examples. You can also find additional information in the [official documenation](https://rdflib.readthedocs.io/en/stable/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQmhRDzUJ3xT","outputId":"488a0cab-2e34-4798-d316-57733f682733","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rdflib in /Users/avijitthawani/opt/miniconda3/envs/hw1/lib/python3.9/site-packages (6.0.0)\n","Requirement already satisfied: isodate in /Users/avijitthawani/opt/miniconda3/envs/hw1/lib/python3.9/site-packages (from rdflib) (0.6.0)\n","Requirement already satisfied: setuptools in /Users/avijitthawani/opt/miniconda3/envs/hw1/lib/python3.9/site-packages (from rdflib) (52.0.0.post20210125)\n","Requirement already satisfied: pyparsing in /Users/avijitthawani/opt/miniconda3/envs/hw1/lib/python3.9/site-packages (from rdflib) (2.4.7)\n","Requirement already satisfied: six in /Users/avijitthawani/opt/miniconda3/envs/hw1/lib/python3.9/site-packages (from isodate->rdflib) (1.16.0)\n"]}],"source":["! pip install rdflib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSlFv0BhJ3xT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF"]},{"cell_type":"markdown","metadata":{"id":"M-loxb1-J3xU","pycharm":{"name":"#%% md\n"}},"source":["Let's define some namespaces:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0SzNXOhJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["FOAF = Namespace('http://xmlns.com/foaf/0.1/')\n","MYNS = Namespace('http://dsci558.org/myfakenamespace#')"]},{"cell_type":"markdown","metadata":{"id":"k7Rul4D1J3xU","pycharm":{"name":"#%% md\n"}},"source":["We can create a graph:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSQH4Uo5J3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["my_kg = Graph()\n","my_kg.bind('myns', MYNS)\n","my_kg.bind('foaf', FOAF)"]},{"cell_type":"markdown","metadata":{"id":"wAY1RbdIJ3xU","pycharm":{"name":"#%% md\n"}},"source":["Define a URI, then add a simple triple to the graph:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3I0EK2ipJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["node_uri = URIRef(MYNS['dsci_558'])\n","my_kg.add((node_uri, RDF.type, MYNS['course']))"]},{"cell_type":"markdown","metadata":{"id":"oof8rvbjJ3xU","pycharm":{"name":"#%% md\n"}},"source":["Add an additional triple (which describes the same subject, `node_uri`):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljxEhaLeJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["my_kg.add((node_uri, FOAF['name'], Literal('Building Knowledge Graphs')))"]},{"cell_type":"markdown","metadata":{"id":"ed_XbkFbJ3xU","pycharm":{"name":"#%% md\n"}},"source":["And now let's dump our graph triples into some `ttl` file:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n2MI9-KKJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["my_kg.serialize(dir_ + 'sample_graph.ttl', format=\"turtle\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIfJgmAvJ3xU","outputId":"f243c52a-40d9-4950-f45e-cc7fbbe0e22e","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n","@prefix myns: <http://dsci558.org/myfakenamespace#> .\n","\n","myns:dsci_558 a myns:course ;\n","    foaf:name \"Building Knowledge Graphs\" .\n","\n"]}],"source":["!head sample_graph.ttl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvnuzp4OJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('DS558')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"7d2ff20c00d4ac93ff3e3c3c2246f9d6a04344282adafe22c7a286cd6fb7db25"}}},"nbformat":4,"nbformat_minor":0}
