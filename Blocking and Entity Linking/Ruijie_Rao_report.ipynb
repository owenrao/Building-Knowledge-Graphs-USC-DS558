{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Entity Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both datasets, I included their name string, name tokens(tokenized by regex only including words), publish date and year, ISBN13 number, author and page count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name_string</th>\n",
       "      <th>author</th>\n",
       "      <th>page_count</th>\n",
       "      <th>name_tokens</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Managing My Life: My Autobiography</td>\n",
       "      <td>Alex Ferguson</td>\n",
       "      <td>531</td>\n",
       "      <td>[managing, my, life, my, autobiography]</td>\n",
       "      <td>9780340728567</td>\n",
       "      <td>2000-08-01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I Remember: Sketch for an Autobiography</td>\n",
       "      <td>Boris Pasternak</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, remember, sketch, for, an, autobiography]</td>\n",
       "      <td>9780844627106</td>\n",
       "      <td>None</td>\n",
       "      <td>GoodRecord Item 1 has no valid publish year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Betty Boothroyd: Autobiography</td>\n",
       "      <td>Betty Boothroyd</td>\n",
       "      <td>384</td>\n",
       "      <td>[betty, boothroyd, autobiography]</td>\n",
       "      <td>9780712679480</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Caddie, A Sydney Barmaid: An Autobiography</td>\n",
       "      <td>Caddie</td>\n",
       "      <td>199</td>\n",
       "      <td>[caddie, a, sydney, barmaid, an, autobiography]</td>\n",
       "      <td>9780725100148</td>\n",
       "      <td>1966-09-15</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Nureyev: An Autobiography With Pictures</td>\n",
       "      <td>Rudolf Nureyev</td>\n",
       "      <td>160</td>\n",
       "      <td>[nureyev, an, autobiography, with, pictures]</td>\n",
       "      <td>9780340014684</td>\n",
       "      <td>1963-09-15</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                 name_string           author page_count  \\\n",
       "0  0          Managing My Life: My Autobiography    Alex Ferguson        531   \n",
       "1  1     I Remember: Sketch for an Autobiography  Boris Pasternak          0   \n",
       "2  2              Betty Boothroyd: Autobiography  Betty Boothroyd        384   \n",
       "3  3  Caddie, A Sydney Barmaid: An Autobiography           Caddie        199   \n",
       "4  4     Nureyev: An Autobiography With Pictures   Rudolf Nureyev        160   \n",
       "\n",
       "                                       name_tokens         ISBN13  \\\n",
       "0          [managing, my, life, my, autobiography]  9780340728567   \n",
       "1    [i, remember, sketch, for, an, autobiography]  9780844627106   \n",
       "2                [betty, boothroyd, autobiography]  9780712679480   \n",
       "3  [caddie, a, sydney, barmaid, an, autobiography]  9780725100148   \n",
       "4     [nureyev, an, autobiography, with, pictures]  9780340014684   \n",
       "\n",
       "  publication_date                             publication_year  \n",
       "0       2000-08-01                                         2000  \n",
       "1             None  GoodRecord Item 1 has no valid publish year  \n",
       "2       2002-11-01                                         2002  \n",
       "3       1966-09-15                                         1966  \n",
       "4       1963-09-15                                         1963  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "good_ds.generate_dataframe().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the following mentions, RR will not be introduced for every blocker since the value is way too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. My first blocker is one using name tokens. The original tokenizer does poorly on tokenizing, since it does not strip away punctuations. To make tokens more standardized, I created a tokenizer that uses regex. This blocker alone generates PC = 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens_block = bg.generate(\n",
    "    bg.block(good_ds, function_=lambda r: \",\".join(r.name_tokens)),\n",
    "    bg.block(noble_ds, function_=lambda r: \",\".join(r.name_tokens))\n",
    ") #0.50,0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The second blocker is a joined blocker composed of publish year and author name. \n",
    "    - The reason to use publish year instead of publish date as a whole is because lots of records in Goods are not standardized or missing. Most of its records atleast have a year of publish, so I choose to slice it out. It proves to be way more effective than using date as a whole. This block alone generates PC=80%.\n",
    "    - Using First author name generates PC=79%.\n",
    "    - The reason to join both blockers together instead of union is that it is nearly impossible for two different books to have the same author AND be published the same year: they must be the same book. The PC of the joined blocker is 64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_block = bg.generate(\n",
    "    bg.block(good_ds, property_='publication_year'),\n",
    "    bg.block(noble_ds, property_='publication_year')\n",
    ") #0.23,0.80\n",
    "\n",
    "author_block = bg.generate(\n",
    "    bg.block(good_ds, property_='author', base_on=year_block),\n",
    "    bg.block(noble_ds, property_='author', base_on=year_block)\n",
    ") #0.69,0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The third blocker uses ISBN13 number. This is a very standardized attribute. Since the equality of ISBN between two books gurantees a matching, this is a perfect but strict blocker. PC=37%, with high Precision=97."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_block = bg.generate(\n",
    "    bg.block(good_ds, property_='ISBN13'),\n",
    "    bg.block(noble_ds, property_='ISBN13')\n",
    ") #0.12,0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, 3 blockers are unioned together. This is because all of them have very narrow filter. Name tokens only allows those books have exactly the same tokens, creates lots of false negative; publish year is not that strict, but blocking with author name is very strict and combining them filters out a lot of books with no publish date records, also creates lots of false negatives; ISBN is a great blocker, but there are books with different ISBN actually matches, thus also creates lots of false negatives. However, their union greatly retrieves those false negaive cases since it is extremely rare for any pair to be the same book while having different author name, publish year, ISBN number and name tokens.\n",
    "\n",
    "As a result, the union blocker generates RR=0.0003, PC=0.97 and precision=0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3: Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I used jaro similarity in the demo, which is not as good as later token cosine sim. option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_jaro_similarity(r1, r2):\n",
    "    s1 = r1.name_string\n",
    "    s2 = r2.name_string\n",
    "    \n",
    "    return rltk.jaro_winkler_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Name tokens cosine similarity score measures the cosine similarity of the tokens. This performs great for books with almost the same wordings. This is used as my main measure of similarity. However, this alone generates good F score while very low precision due to lots of false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(vec1,vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def name_tokens_cos_similarity(r1, r2):\n",
    "    vec1 = Counter(r1.name_tokens)\n",
    "    vec2 = Counter(r2.name_tokens)\n",
    "    return cos_similarity(vec1,vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tried to lower the false negativity using the author names, but did not work out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_tokens_cos_similarity(r1, r2):\n",
    "    vec1 = Counter(my_tokenizer(r1.author))\n",
    "    vec2 = Counter(my_tokenizer(r2.author))\n",
    "    return cos_similarity(vec1,vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ISBN is always the best gurantee. This is used as the filter of my measure: if a pair passes ISBN equality check, they automatically passes with a confidence of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISBN_equality(r1, r2):\n",
    "    if r1.ISBN13 == r2.ISBN13:\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. To address the high false positivity issue generated by #2, publish year equality is used. This is more like a filter at the very end, to throw away those books with high name similarities but are published in different years.\n",
    "    - If the books have different publish years, they got a hard 0 for the score.\n",
    "    - If the books have the same year of one of them do not have valid record, that means there is still chance of 50% that they are matches. Thus, a score of 0.5 is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_year_equality(r1, r2):\n",
    "    y1 = r1.publication_year\n",
    "    y2 = r2.publication_year\n",
    "    if y1 == y2:\n",
    "        return 0.5\n",
    "    else:\n",
    "        try:\n",
    "            _ = int(y1)\n",
    "            _ = int(y2)\n",
    "            return 0\n",
    "        except:\n",
    "            return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, I picked and chose the measure functions and set my parameters by testing out each combination. This following combination generates the best result: \n",
    "- precison: 0.9180327868852459 recall: 0.835820895522388 f-measure: 0.875\n",
    "- tp: 0.835821 [56]\n",
    "- fp: 0.021739 [5]\n",
    "- tn: 0.978261 [225]\n",
    "- fn: 0.164179 [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_TRESH = 0.83\n",
    "\n",
    "def rule_based_method(r1, r2):\n",
    "    if ISBN_equality(r1, r2)==1:\n",
    "        return True,1\n",
    "    score_1 = publish_year_equality(r1, r2)\n",
    "    score_2 = name_tokens_cos_similarity(r1, r2)\n",
    "    \n",
    "    total = 0.2 * score_1 + 0.75 * score_2\n",
    "    return total > MY_TRESH, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Knowledge Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Model Construct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name Space wise I included ISBNDB.com for the URIs of book subjects, schema.org and dbpedia.org for properties and classes, and myns for self created subproperties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOAF = Namespace('http://xmlns.com/foaf/0.1/')\n",
    "SCHEMA = Namespace('https://schema.org/')\n",
    "ISBN = Namespace('https://isbndb.com/book/')\n",
    "DBPD = Namespace('https://dbpedia.org/ontology/')\n",
    "MYNS = Namespace('http://dsci558.org/myfakenamespace#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct one subject, first I define its URI using isbndb.com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = URIRef(ISBN[row[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the record doesn's has one, then I create one using its id and its reference origin. The reason not to use only thier id is that there can be occasions when id131 from Goodreads and id131 from Nobles both exist, which will result in confusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = f\"good_{row[0]}\"\n",
    "subject = MYNS[id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I use schema.org to set the class of subject to Book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.add((subject, RDF.type, SCHEMA.Book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also set its archived origin using schema:archivedAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.add((subject, SCHEMA.archivedAt, Literal(\"https://www.goodreads.com/\")))\n",
    "my_kg.add((subject, SCHEMA.archivedAt, Literal(\"https://www.barnesandnoble.com/\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the other attributes, I find their corresponding property from my namespaces IF there exists a valid record. I also set the datatype for all the attributes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if row[3].strip(): my_kg.add((subject, SCHEMA.isbn, Literal(row[3])))\n",
    "if row[12].strip(): my_kg.add((subject, SCHEMA.publisher, Literal(row[12], datatype=SCHEMA.Organization)))\n",
    "if row[13].strip(): my_kg.add((subject, SCHEMA.datePublished, Literal(row[13], datatype=SCHEMA.Date)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also used blank nodes for defining nested elements like reviews and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating\n",
    "        my_kg.add((BNode(\"rating_\"+id), RDF.type, SCHEMA.AggregateRating))\n",
    "        my_kg.add((BNode(\"rating_\"+id), SCHEMA.ratingValue, Literal(row[9], datatype=XSD.float)))\n",
    "        my_kg.add((BNode(\"rating_\"+id), SCHEMA.ratingCount, Literal(row[10], datatype=XSD.integer)))\n",
    "        my_kg.add((subject, SCHEMA.aggregateRating, BNode(\"rating_\"+id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also created a few self-defined properties for Nobles and Barnes' records, like salesRank and paperbackPrice. I defined its type as property, its subclassOf, range and domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.add((MYNS[\"salesRank\"], RDF.type, RDF.Property))\n",
    "my_kg.add((MYNS[\"salesRank\"], RDFS.subPropertyOf, DBPD.rank))\n",
    "my_kg.add((MYNS[\"salesRank\"], RDFS.domain, SCHEMA.Book))\n",
    "my_kg.add((MYNS[\"salesRank\"], RDFS.range, XSD.integer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why I seperated the matching pairs is because in most cases matching subjects still differs a lot regarding their name, page count, author name and ratings. My design thus persists their original data while matching them using the property RDFS:seeAlso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kg.add((r1_subject, RDFS.seeAlso, r2_subject))\n",
    "my_kg.add((r2_subject, RDFS.seeAlso, r1_subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I found it impossible for the RDG Grapher to graph the whole KG, not even 20 of the entries. As a result, I sampled about 10 of them and try to include all the situations I designed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DS558')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d2ff20c00d4ac93ff3e3c3c2246f9d6a04344282adafe22c7a286cd6fb7db25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
